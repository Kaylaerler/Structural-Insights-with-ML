activation: leaky_relu
batch_size: 512
dropout_prob: 0.1
hidden_layers: 2
hidden_neurons: 16
learning_rate: 0.001
num_epochs: 20
