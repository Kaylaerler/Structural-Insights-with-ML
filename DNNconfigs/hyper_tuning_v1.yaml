# Hyperparameter tuning configuration file

# Number of neurons to be used in each hidden layer
hidden_neurons: [1, 2, 4, 8, 16]

# Number of hidden layers to be used in the network
hidden_layers: [1, 2, 4, 8, 16, 32] 

# Type of non-linear activation function to be used for all layers
activation: ['leaky_relu']

# The learning rate to be used for training.
learning_rate: [0.001, 0.0001]

# Number of training samples per batch to be passed to network
batch_size: [512, 1024]

# Number of epochs to train the model
num_epochs: [20]

# drop out probability
dropout_prob: [0.1, 0.2, 0.3, 0.4, 0.5]