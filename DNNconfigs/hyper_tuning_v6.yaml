# Hyperparameter tuning configuration file

# Number of neurons to be used in each hidden layer
hidden_neurons: [2, 4, 8, 16, 32, 64]

# Number of hidden layers to be used in the network
hidden_layers: [2, 4, 8, 16] 

# Type of non-linear activation function to be used for all layers
activation: ['leaky_relu']

# The learning rate to be used for training.
learning_rate: [0.01, 0.005, 0.001]

# Number of training samples per batch to be passed to network
batch_size: [1024]

# Number of epochs to train the model
num_epochs: [20]

# drop out probability
dropout_prob: [0, 0.1]